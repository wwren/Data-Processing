{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elements Of Data Processing (2020S2) - Week 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular expressions \n",
    "Regular expressions allow you to match patterns in strings, rather than matching exact characters.  \n",
    "For example, \n",
    "if I wished to find all phone numbers of the form (03) xxxx xxxx, where x is some arbitrary digit, \n",
    "I could use a regular expression like this: \n",
    "    \n",
    "\\(03\\) \\d\\d\\d\\d \\d\\d\\d\\d\n",
    "\n",
    "*or*\n",
    "\n",
    "\\(03\\) \\d{4} \\d4}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **re** library in python allows you to use regular expressions.  It provides a number of useful functions, \n",
    "including:\n",
    "    \n",
    "***search*** - Searches for a particular pattern in a string | return boolean: True, False\n",
    "\n",
    "***findall*** - Finds all substrings that match a particular pattern\n",
    "\n",
    "***sub*** - Replaces substrings that match a particular pattern with a new substring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### This example looks for phone numbers that match the format above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone number found\n"
     ]
    }
   ],
   "source": [
    "#This examples looks for phone numbers that match the format above\n",
    "import re\n",
    "\n",
    "string = r'Name: Chris, ph: (03) 9923 1123, comments: this is not my real number'\n",
    "# r' ' means the string is to be treated as a raw string...escape codes will be ignored\n",
    "# for example '\\n' means new line; r'\\n' means \\ and n \n",
    "# but r\"\\\" is not a valid string...since the backslash would escape the following qupte character \n",
    "pattern = r'\\(03\\) \\d{4} \\d{4,4}' #{min repetition, max repetition}\n",
    "# even though r' ' means regular expression, when parse to re.method its matacharacter has special meaning\n",
    "if re.search(pattern, string) :\n",
    "    print(\"Phone number found\")\n",
    "else :\n",
    "    print(\"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "string = r'\\s('\n",
    "pattern = r'\\s'\n",
    "#\\S is anything but space\n",
    "if re.search(pattern, string):\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone number found\n",
      "Phone number found\n",
      "Phone number found\n",
      "Phone number found\n",
      "Phone number found\n",
      "Phone number found\n"
     ]
    }
   ],
   "source": [
    "strings = [\n",
    "    r'a[c',\n",
    "    r'a.c',\n",
    "    r'acc',\n",
    "    r'a/c',\n",
    "    r'acccc',\n",
    "    r'acacc'\n",
    "]\n",
    "\n",
    "pattern = r'a.c'\n",
    "#special characters lose their special meaning inside sets: [(+*)] will match any of literal characters [, (, +, *, ), ]\n",
    "#so if do this pattern = r'a[.]c' will only match r'a.c'\n",
    "for s in strings:\n",
    "    if re.search(pattern, s) :\n",
    "        print(\"Phone number found\")\n",
    "    else :\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 1 </span>\n",
    "\n",
    "Modify the example above so that it will also find phone numbers starting with 03 that:\n",
    "    \n",
    "- are missing brackets and/or\n",
    "- instead of a space, use hyphens,  backslashes and/or spaces.\n",
    "\n",
    "Your program should match all elements in ***strings*** in the code segment below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone number found\n",
      "Phone number found\n",
      "Phone number found\n",
      "Phone number found\n"
     ]
    }
   ],
   "source": [
    "#This examples looks for phone numbers that match the format above\n",
    "import re\n",
    "strings = [\n",
    "    r'Name: Chris, ph: (03) 9923 1123, comments: this is not my real number',\n",
    "    r'Name: John, ph: 03-9923-1123, comments: this might be an old number',\n",
    "    r'Name: Sara, phone: (03)-9923-1123, comments: there is data quality issues, so far, three people sharig the same number',\n",
    "    r'Name: Christopher, ph: (03)\\-9923 -1123, comments, is this the same Chris in the first record?'\n",
    "]\n",
    "\n",
    "#change this line\n",
    "pattern =  r'\\(?03\\)?[-\\\\\\s]*\\d{4}[-\\\\\\s]*\\d{4,4}'\n",
    "#? exist or not: 0-1\n",
    "#[]means looks for some group / set => but only one repetition => 0 or more repetition\n",
    "#\\s means space\n",
    "#[\\\\-\\s]* looking for an element in the set and repeate \n",
    "#[\\\\-\\s]* didnt not work initially -> change order in the set, order matters\n",
    "\n",
    "for s in strings:\n",
    "    if re.search(pattern, s) :\n",
    "        print(\"Phone number found\")\n",
    "    else :\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 2 </span>\n",
    "\n",
    "Write a program that will remove all leading zeros from an IP address\n",
    "    \n",
    "For example, 0216.08.094.102 should become 216.8.94.196\n",
    "\n",
    "Your program should match all elements in ***strings*** in the code segment below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.8.94.102\n"
     ]
    }
   ],
   "source": [
    "#Exercise 2: Write a program that will remove all leading zeros from an IP address\n",
    "#For example, 0216.08.094.102 should become 216.8.94.196\n",
    "import re\n",
    "\n",
    "ip_addr = '0216.08.094.102'\n",
    "#first find leading 0 character\n",
    "#replace with empty string\n",
    "pattern = r'^0'\n",
    "replace =r''\n",
    "revised_addr = re.sub(pattern, replace, ip_addr)\n",
    "#second find literal .0 \n",
    "#replace with literal .\n",
    "pattern2 = r'\\.0' #want pattern to be literal . need to escape \n",
    "replace2 = r'.'\n",
    "revised_addr2 = re.sub(pattern2, replace2, revised_addr)\n",
    "print(revised_addr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.8.94.102\n"
     ]
    }
   ],
   "source": [
    "#will find all regular expression inside the ()\n",
    "#so need to use | (or)\n",
    "pattern = r'(^|\\.)0'\n",
    "revised_addr = re.sub(pattern, r'\\1', ip_addr)\n",
    "print(revised_addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing ##\n",
    "The ***nltk*** library provides you with tools for natural language processing, including tokenizing, stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "# if running the first time with errors:\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#like java, create an object of type PoterStemmer()\n",
    "porterStemmer = PorterStemmer()\n",
    "#word tokenization\n",
    "speech = 'Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal. Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this. But, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.'\n",
    "wordList = nltk.word_tokenize(speech)\n",
    "# download stopwords object:\n",
    "from nltk.corpus import stopwords\n",
    "#stopwords object has method stopwords.words() set language to be english\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "#[] a list of w: rules - loop through wordList if w not in stopwords\n",
    "# filteredList = []\n",
    "# for w in wordList:\n",
    "#     if w not in stopWords:\n",
    "#         filteredList.append(w)\n",
    "\n",
    "filteredList = [w for w in wordList if not w in stopWords] #1\n",
    "for word in filteredList:\n",
    "    stemWord = porterStemmer.stem(word)\n",
    "    \n",
    "wordDict = {}\n",
    "for word in filteredList:\n",
    "    stemWord = porterStemmer.stem(word)\n",
    "    if stemWord in wordDict : \n",
    "        wordDict[stemWord] = wordDict[stemWord] +1\n",
    "    else :\n",
    "        wordDict[stemWord] = 1\n",
    "wordDict = {k: v for k, v in sorted(wordDict.items(), key=lambda item: item[1], reverse=True)} #2\n",
    "#similar one liner structure as #1\n",
    "# for key in wordDict: \n",
    "#     print(key, wordDict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(',', 22), ('.', 10), ('--', 7), ('dedic', 6), ('nation', 5), ('live', 4), ('great', 3), ('It', 3), ('dead', 3), ('us', 3), ('shall', 3), ('peopl', 3), ('new', 2), ('conceiv', 2), ('men', 2), ('war', 2), ('long', 2), ('We', 2), ('gave', 2), ('consecr', 2), ('the', 2), ('far', 2), ('rather', 2), ('devot', 2), ('four', 1), ('score', 1), ('seven', 1), ('year', 1), ('ago', 1), ('father', 1), ('brought', 1), ('forth', 1), ('contin', 1), ('liberti', 1), ('proposit', 1), ('creat', 1), ('equal', 1), ('now', 1), ('engag', 1), ('civil', 1), ('test', 1), ('whether', 1), ('endur', 1), ('met', 1), ('battle-field', 1), ('come', 1), ('portion', 1), ('field', 1), ('final', 1), ('rest', 1), ('place', 1), ('might', 1), ('altogeth', 1), ('fit', 1), ('proper', 1), ('but', 1), ('larger', 1), ('sens', 1), ('hallow', 1), ('ground', 1), ('brave', 1), ('struggl', 1), ('poor', 1), ('power', 1), ('add', 1), ('detract', 1), ('world', 1), ('littl', 1), ('note', 1), ('rememb', 1), ('say', 1), ('never', 1), ('forget', 1), ('unfinish', 1), ('work', 1), ('fought', 1), ('thu', 1), ('nobli', 1), ('advanc', 1), ('task', 1), ('remain', 1), ('honor', 1), ('take', 1), ('increas', 1), ('caus', 1), ('last', 1), ('full', 1), ('measur', 1), ('highli', 1), ('resolv', 1), ('die', 1), ('vain', 1), ('god', 1), ('birth', 1), ('freedom', 1), ('govern', 1), ('perish', 1), ('earth', 1)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it is a dict_item\n",
    "wordDict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 'short', 'red', 9], [12, 'tall', 'blue', 1], [4, 'tall', 'blue', 13]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more lambda explained\n",
    "# lambda is an anynomous function, it doesn't need a name! aks doesn't need to be assigned to anything\n",
    "# if wants to assign a name, use def methodName():\n",
    "# more explained: https://stackoverflow.com/questions/8966538/syntax-behind-sortedkey-lambda\n",
    "s = [[12, 'tall', 'blue', 1],\n",
    "[2, 'short', 'red', 9],\n",
    "[4, 'tall', 'blue', 13]]\n",
    "# x refers to each element in s\n",
    "# x is a list\n",
    "#x[1]: tall, short, tall\n",
    "#x[2]: blue, red, blue\n",
    "s = sorted(s, key = lambda x: (x[1], x[2]))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(any iterable, key=)\n",
    "# list.sorted() only accept list\n",
    "student_tuples = [\n",
    "    ('john', 'A', 15),\n",
    "    ('jane', 'B', 12),\n",
    "    ('dave', 'B', 10),]\n",
    "sorted(student_tuples, key=lambda student: student[2]) \n",
    "#lambda key = lambda argument : expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 3 </span>\n",
    "\n",
    "Modify the example above to use a WordNet Lemmatizer instead of a porter stemmer.\n",
    "\n",
    "Comment on the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Solution to Exercise 3: \n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "nltk.download('wordnet')\n",
    "# This part is a bit like java: Scanner keyboard = new Scanner()\n",
    "# to create an object from Scanner class => this object will have corresponding properties and methods from this class\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 22\n",
      ". 10\n",
      "-- 7\n",
      "nation 5\n",
      "dedicated 4\n",
      "great 3\n",
      "It 3\n",
      "dead 3\n",
      "u 3\n",
      "shall 3\n",
      "people 3\n",
      "new 2\n",
      "conceived 2\n",
      "men 2\n",
      "war 2\n",
      "long 2\n",
      "We 2\n",
      "dedicate 2\n",
      "gave 2\n",
      "The 2\n",
      "living 2\n",
      "far 2\n",
      "rather 2\n",
      "devotion 2\n",
      "Four 1\n",
      "score 1\n",
      "seven 1\n",
      "year 1\n",
      "ago 1\n",
      "father 1\n",
      "brought 1\n",
      "forth 1\n",
      "continent 1\n",
      "Liberty 1\n",
      "proposition 1\n",
      "created 1\n",
      "equal 1\n",
      "Now 1\n",
      "engaged 1\n",
      "civil 1\n",
      "testing 1\n",
      "whether 1\n",
      "endure 1\n",
      "met 1\n",
      "battle-field 1\n",
      "come 1\n",
      "portion 1\n",
      "field 1\n",
      "final 1\n",
      "resting 1\n",
      "place 1\n",
      "life 1\n",
      "might 1\n",
      "live 1\n",
      "altogether 1\n",
      "fitting 1\n",
      "proper 1\n",
      "But 1\n",
      "larger 1\n",
      "sense 1\n",
      "consecrate 1\n",
      "hallow 1\n",
      "ground 1\n",
      "brave 1\n",
      "struggled 1\n",
      "consecrated 1\n",
      "poor 1\n",
      "power 1\n",
      "add 1\n",
      "detract 1\n",
      "world 1\n",
      "little 1\n",
      "note 1\n",
      "remember 1\n",
      "say 1\n",
      "never 1\n",
      "forget 1\n",
      "unfinished 1\n",
      "work 1\n",
      "fought 1\n",
      "thus 1\n",
      "nobly 1\n",
      "advanced 1\n",
      "task 1\n",
      "remaining 1\n",
      "honored 1\n",
      "take 1\n",
      "increased 1\n",
      "cause 1\n",
      "last 1\n",
      "full 1\n",
      "measure 1\n",
      "highly 1\n",
      "resolve 1\n",
      "died 1\n",
      "vain 1\n",
      "God 1\n",
      "birth 1\n",
      "freedom 1\n",
      "government 1\n",
      "perish 1\n",
      "earth 1\n"
     ]
    }
   ],
   "source": [
    "#create a dic\n",
    "lemmaDict = {}\n",
    "for word in filteredList:\n",
    "    lemmaWord = lemmatizer.lemmatize(word)\n",
    "    if lemmaWord in lemmaDict : \n",
    "        lemmaDict[lemmaWord] = lemmaDict[lemmaWord] +1\n",
    "    else :\n",
    "        lemmaDict[lemmaWord] = 1\n",
    "\n",
    "lemmaDict = {k: v for k, v in sorted(lemmaDict.items(), key= lambda item: item[1], reverse = True)}\n",
    "for item in lemmaDict:\n",
    "    #print(item + \": \"+ str(lemmaDict[item]))\n",
    "    print(item, lemmaDict[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
